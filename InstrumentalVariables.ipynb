{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumental Variables\n",
    "\n",
    "by Jonas Peters, Niklas Pfister, Martin Emil Jakobsen and Rune Christiansen, 21.06.2019\n",
    "\n",
    "This notebook aims to give you a basic understanding of the instrumental variable approach and when it can be used to infer causal relations.\n",
    "\n",
    "In the following, let all variables have \n",
    "* zero mean,  \n",
    "* finite second moments, and\n",
    "* their joint distribution is absolutely continuous with respect to the Lebesgue measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.libPaths(\"C:/ProgramData/Anaconda3/Lib/R/library\");\n",
    "#install.packages(\"AER\",repos = \"http://cran.us.r-project.org\");\n",
    "library(AER);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrumental Variable Model\n",
    "\n",
    "The goal of this method is to estimate the causal effect of a predictor variable $X$ on a target variable $Y$ if the effect from $X$ to $Y$ is confounded. The idea of the instrumental variable approach is to account for this confounding by considering an additional variable $I$ called an instrument. Although there exist numerous extensions, here, we focus on the classical case. We provide two definitions.\n",
    "\n",
    "\n",
    "First, assume the following SCM\n",
    "\\begin{align}\n",
    "I &:= N_I\\\\\n",
    "H &:= N_H\\\\ \n",
    "X &:= I \\gamma  + H \\delta_X + N_X\\\\\n",
    "Y &:= X \\beta + H \\delta_Y + N_Y.\\\\\n",
    "\\end{align}\n",
    "(All variables except $Y$ could be multi-dimensional, in which case, they should be written as row vectors: $1 \\times d$.) If all variables are $1$-dimensional, the corresponding DAG looks as follows.\n",
    "\\begin{align}\n",
    "    &\\phantom{0}\\\\\n",
    "    &\\begin{array}{ccc}\n",
    "       & & &H                 & \\\\\n",
    "       & &\\phantom{abcdefgh}\\overset{\\delta_X}{\\swarrow} &            & \\overset{\\delta_Y}{\\searrow}\\phantom{abcdefgh}\\\\\n",
    "       & &                    &               & \\\\\n",
    "       I &\\overset{\\gamma}{\\longrightarrow} &X                  & \\overset{\\beta}{\\longrightarrow} & Y\\\\\n",
    "        \\end{array}\\\\\n",
    "      &\\phantom{0}\n",
    "\\end{align}\n",
    "Here, $I$ is called an instrumental variable for the causal effect from $X$ to $Y$. It is essential that $I$ effects $Y$ only via $X$ (and not directly).\n",
    "\n",
    "\n",
    "\n",
    "Second, it is possible to define instrumental variables without SCMs, too. Let us therefore write\n",
    "\\begin{equation}\n",
    "Y =  X \\beta + \\epsilon_Y\n",
    "\\end{equation}\n",
    "(this can always be done). Here, $\\epsilon_Y$ is allowed to depend on $X$ (if there is a confounder $H$ between $X$ and $Y$, this is usually the case). We then call a variable $I$ an instrumental variable if it satisfies the following three conditions:\n",
    "1. $\\operatorname{cov}(X,I)$ is of full rank (relevance).\n",
    "2. $\\operatorname{cov}(\\epsilon_Y,I)=0$ (exogenity).\n",
    "3. $\\operatorname{cov}(I)$ is of full rank. \n",
    "\n",
    "Informally speaking, these conditions again mean that $I$ affects $Y$ ''only through its effect on $X$''."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "We now want to illustrate how the existence of an instrumental variable $I$ can be used to estimate the causal effect $\\beta$ in the model above. Let us therefore assume that we have received data in matrix form\n",
    "* $\\mathbf{Y}$ - the target variable $n \\times 1$ \n",
    "* $\\mathbf{X}$ - the covariates $n \\times d$\n",
    "* $\\mathbf{I}$ - the instruments $n \\times m$\n",
    "\n",
    "where $n > \\max(m, d)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now assume that $I$ is a valid instrument (we come back to this question in Exercise 2 below). To estimate the causal effect of $X$ on $Y$, there are several options of writing down the same estimator. \n",
    "\n",
    "OPTION 1: The following estimator is sometimes called the generalized methods of moments (GMM)\n",
    "$$\n",
    "\\hat{\\beta}^{GMM}_n := (\\mathbf{X}^t \\mathbf{I} (\\mathbf{I}^t \\mathbf{I})^{-1} \\mathbf{I}^t \\mathbf{X})^{-1} \\, \\mathbf{X}^t \\mathbf{I} (\\mathbf{I}^t \\mathbf{I})^{-1} \\mathbf{I}^t \\mathbf{Y}\n",
    "$$\n",
    "\n",
    "OPTION 2: \n",
    "we can use a so-called 2-stage least squares (2SLS) procedure. Step 1: Regress $X$ on $I$ and compute the corresponding fitted values $\\hat{X}$. Step 2: Regress $Y$ on $\\hat{X}$. Use the regression coefficients from step 2. \n",
    "\n",
    "The following four exercises go over some of the details of the 2SLS and apply it to a real data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Assume that the data are i.i.d. from the following two structural assignments \n",
    "\\begin{align*}\n",
    "Y &:= X \\cdot \\beta + \\epsilon_Y \\\\\n",
    "X &:= I \\cdot \\gamma + \\epsilon_X,\n",
    "\\end{align*}\n",
    "where $X$ and $I$ are written as $1 \\times d$ and $1 \\times m$ vectors, respectively. Here, $\\epsilon_X$ and $\\epsilon_Y$ are not necessarily independent, but the instrument $I$ is assumed to satisfy the assumptions 1., 2., and 3. above. \n",
    "\n",
    "a) Write down conditions on $d$ and $m$ that guarantee that $\\hat{\\beta}^{GMM}_n$ is well-defined (with probability one). You may assume that the sample versions $\\mathbf{I}^t \\mathbf{I}$ and $\\mathbf{I}^t \\mathbf{X}$ of instrumental varible condition 1) and 3) are of full rank. \n",
    "\n",
    "** <i>Hint: Prove that for a specific ordering of $d$ and $m$ (e.g. $d\\leq m$, $d\\geq m$ etc.) the matrix $\\mathbf{X}^t \\mathbf{I} (\\mathbf{I}^t \\mathbf{I})^{-1} \\mathbf{I}^t \\mathbf{X}$ inverted in the GMM estimator is positive definite, hence invertible.  </i> **\n",
    "\n",
    "b) Prove that under these conditions that the GMM method is consistent towards the causal parameter, i.e., $\\hat{\\beta}^{GMM}_n \\rightarrow \\beta$ in probability. \n",
    "\n",
    "** <i>Hint: Use the model specification from above to write $\\hat{\\beta}^{GMM}_n$ as $\\beta$ plus a remainder term that is a linear function of $\\epsilon_Y$. Then use the continuous mapping theorem, which states that you may apply a continuous mapping on both sides of a convergence in probability expression, if the mapping in continuous in the limiting expression (Note that the inverse operator on matrices $M \\stackrel{\\text{Inv.}}{\\mapsto} M^{-1}$ is continuous). Finally, use the fact that the product of two random sequences, each of which converge in probability to a constant, converges in probability to the product of these constants.  </i> **\n",
    "\n",
    "c) Assume $d \\leq  m$. Prove that the methods 2SLS and GMM provide the same estimate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Solution 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration, we use the <tt>CollegeDistance</tt> data set from [1] available in the R package <tt>AER</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>gender</th><th scope=col>ethnicity</th><th scope=col>score</th><th scope=col>fcollege</th><th scope=col>mcollege</th><th scope=col>home</th><th scope=col>urban</th><th scope=col>unemp</th><th scope=col>wage</th><th scope=col>distance</th><th scope=col>tuition</th><th scope=col>education</th><th scope=col>income</th><th scope=col>region</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>male   </td><td>other  </td><td>39.15  </td><td>yes    </td><td>no     </td><td>yes    </td><td>yes    </td><td>6.2    </td><td>8.09   </td><td>0.2    </td><td>0.88915</td><td>12     </td><td>high   </td><td>other  </td></tr>\n",
       "\t<tr><td>female </td><td>other  </td><td>48.87  </td><td>no     </td><td>no     </td><td>yes    </td><td>yes    </td><td>6.2    </td><td>8.09   </td><td>0.2    </td><td>0.88915</td><td>12     </td><td>low    </td><td>other  </td></tr>\n",
       "\t<tr><td>male   </td><td>other  </td><td>48.74  </td><td>no     </td><td>no     </td><td>yes    </td><td>yes    </td><td>6.2    </td><td>8.09   </td><td>0.2    </td><td>0.88915</td><td>12     </td><td>low    </td><td>other  </td></tr>\n",
       "\t<tr><td>male   </td><td>afam   </td><td>40.40  </td><td>no     </td><td>no     </td><td>yes    </td><td>yes    </td><td>6.2    </td><td>8.09   </td><td>0.2    </td><td>0.88915</td><td>12     </td><td>low    </td><td>other  </td></tr>\n",
       "\t<tr><td>female </td><td>other  </td><td>40.48  </td><td>no     </td><td>no     </td><td>no     </td><td>yes    </td><td>5.6    </td><td>8.09   </td><td>0.4    </td><td>0.88915</td><td>13     </td><td>low    </td><td>other  </td></tr>\n",
       "\t<tr><td>male   </td><td>other  </td><td>54.71  </td><td>no     </td><td>no     </td><td>yes    </td><td>yes    </td><td>5.6    </td><td>8.09   </td><td>0.4    </td><td>0.88915</td><td>12     </td><td>low    </td><td>other  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllll}\n",
       " gender & ethnicity & score & fcollege & mcollege & home & urban & unemp & wage & distance & tuition & education & income & region\\\\\n",
       "\\hline\n",
       "\t male    & other   & 39.15   & yes     & no      & yes     & yes     & 6.2     & 8.09    & 0.2     & 0.88915 & 12      & high    & other  \\\\\n",
       "\t female  & other   & 48.87   & no      & no      & yes     & yes     & 6.2     & 8.09    & 0.2     & 0.88915 & 12      & low     & other  \\\\\n",
       "\t male    & other   & 48.74   & no      & no      & yes     & yes     & 6.2     & 8.09    & 0.2     & 0.88915 & 12      & low     & other  \\\\\n",
       "\t male    & afam    & 40.40   & no      & no      & yes     & yes     & 6.2     & 8.09    & 0.2     & 0.88915 & 12      & low     & other  \\\\\n",
       "\t female  & other   & 40.48   & no      & no      & no      & yes     & 5.6     & 8.09    & 0.4     & 0.88915 & 13      & low     & other  \\\\\n",
       "\t male    & other   & 54.71   & no      & no      & yes     & yes     & 5.6     & 8.09    & 0.4     & 0.88915 & 12      & low     & other  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "gender | ethnicity | score | fcollege | mcollege | home | urban | unemp | wage | distance | tuition | education | income | region | \n",
       "|---|---|---|---|---|---|\n",
       "| male    | other   | 39.15   | yes     | no      | yes     | yes     | 6.2     | 8.09    | 0.2     | 0.88915 | 12      | high    | other   | \n",
       "| female  | other   | 48.87   | no      | no      | yes     | yes     | 6.2     | 8.09    | 0.2     | 0.88915 | 12      | low     | other   | \n",
       "| male    | other   | 48.74   | no      | no      | yes     | yes     | 6.2     | 8.09    | 0.2     | 0.88915 | 12      | low     | other   | \n",
       "| male    | afam    | 40.40   | no      | no      | yes     | yes     | 6.2     | 8.09    | 0.2     | 0.88915 | 12      | low     | other   | \n",
       "| female  | other   | 40.48   | no      | no      | no      | yes     | 5.6     | 8.09    | 0.4     | 0.88915 | 13      | low     | other   | \n",
       "| male    | other   | 54.71   | no      | no      | yes     | yes     | 5.6     | 8.09    | 0.4     | 0.88915 | 12      | low     | other   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  gender ethnicity score fcollege mcollege home urban unemp wage distance\n",
       "1 male   other     39.15 yes      no       yes  yes   6.2   8.09 0.2     \n",
       "2 female other     48.87 no       no       yes  yes   6.2   8.09 0.2     \n",
       "3 male   other     48.74 no       no       yes  yes   6.2   8.09 0.2     \n",
       "4 male   afam      40.40 no       no       yes  yes   6.2   8.09 0.2     \n",
       "5 female other     40.48 no       no       no   yes   5.6   8.09 0.4     \n",
       "6 male   other     54.71 no       no       yes  yes   5.6   8.09 0.4     \n",
       "  tuition education income region\n",
       "1 0.88915 12        high   other \n",
       "2 0.88915 12        low    other \n",
       "3 0.88915 12        low    other \n",
       "4 0.88915 12        low    other \n",
       "5 0.88915 13        low    other \n",
       "6 0.88915 12        low    other "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load CollegeDistance data set\n",
    "data(\"CollegeDistance\")\n",
    "head(CollegeDistance)\n",
    "# read out relevant variables\n",
    "Y <- CollegeDistance$score\n",
    "X <- CollegeDistance$education\n",
    "I <- CollegeDistance$distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set consists of $4739$ observations on $14$ variables from high school student survey conducted by the Department of Education in $1980$, with a follow-up in $1986$. In this notebook, we only consider the following variables:\n",
    "* $Y$ - base year composite test score.  These are achievement tests given to high school seniors in the sample.\n",
    "* $X$ - number of years of education.\n",
    "* $I$ - distance from closest 4-year college (units are in 10 miles).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Argue whether the variable $I$ can be used as an instrumental variable to infer the causal effect of $X$ on $Y$. Are there arguments, why it might not be a valid instrument? <i> Hint: You can perform a linear regresssion and use the corresponding t-test p-value for significant regression coefficient. This is indeed identical to the t-test for the peasons correlation test-statistic. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Use 2SLS to estimate the causal effect of $X$ on $Y$ based on the instrument $I$. Compare your results with a standard OLS regression of $Y$ on $X$ (that includes an intercept). What happens to the correlation between $X$ and the residuals in both methods? Which attempt yields smaller variance of residuals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Solution 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly different approach to 2SLS is to use the formula\n",
    "\n",
    "OPTION 3:\n",
    "\\begin{equation} \\tag{1}\n",
    "\\hat{\\beta}_n = (\\mathbf{I}^t \\mathbf{X})^{-1} \\mathbf{I}^t \\mathbf{Y}.\n",
    "\\end{equation}\n",
    "\n",
    "If $d=m$, this formula yields the same estimator as OPTIONS 1 and 2.\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Statement:</b> <i>When $m=d$ we have that the GMM and 2SLS estimators have the reduced form</i>\n",
    " $$\n",
    " \\hat{\\beta}^{GMM}_n= \\hat{\\beta}^{2SLS}_n = (\\mathbf{I}^t \\mathbf{X})^{-1}\\mathbf{I}^t \\mathbf{Y}  \n",
    " $$\n",
    " <i>Proof:</i> Let $ P_I =\\mathbf{I} (\\mathbf{I}^t\\mathbf{I})^{-1}\\mathbf{I}^t$ be the orthogonal projection onto the column space of $\\mathbf{I}$.  We then have \n",
    " $$\n",
    " P_I \\mathbf{X}= \\mathbf{I} (\\mathbf{I}^t\\mathbf{I})^{-1}\\mathbf{I}^t\\mathbf{X} = \\mathbf{I}\\mathbf{Z},\n",
    " $$\n",
    " where $\\mathbf{Z}:=  (\\mathbf{I}^t\\mathbf{I})^{-1}\\mathbf{I}^t\\mathbf{X}$ is invertible, as it is the product of two invertible matrices. Using that $(\\mathbf{Z}^t \\mathbf{I}^t \\mathbf{X})^{-1}= (\\mathbf{I}^t \\mathbf{X})^{-1}(\\mathbf{Z}^t)^{-1}$, we then get \n",
    " \\begin{align*}\n",
    " \\hat{\\beta}^{GMM}_n &= (\\mathbf{X}^t \\mathbf{I} (\\mathbf{I}^t\\mathbf{I})^{-1}\\mathbf{I}^t\\mathbf{X})^{-1} \\mathbf{X}^t \\mathbf{I}(\\mathbf{I}^t\\mathbf{I})^{-1} \\mathbf{I}^t  \\mathbf{Y}  \\\\\n",
    " &= ((P_I\\mathbf{X})^t \\mathbf{X})^{-1} (P_I\\mathbf{X})^t \\mathbf{Y} \\\\\n",
    " &= (\\mathbf{Z}^t \\mathbf{I}^t \\mathbf{X})^{-1} \\mathbf{Z}^t \\mathbf{I}^t \\mathbf{Y} \\\\\n",
    " &= (\\mathbf{I}^t \\mathbf{X})^{-1} (\\mathbf{Z}^t)^{-1}  \\mathbf{Z}^t \\mathbf{I}^t \\mathbf{Y} \\\\\n",
    "  &= (\\mathbf{I}^t \\mathbf{X})^{-1}  \\mathbf{I}^t \\mathbf{Y}\n",
    " \\end{align*}\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Apply the above estimator (1) to <tt>CollegeDistance</tt> data and compare your result with the one from Exercise 3. (If you have included intercepts in the 2SLS, you need to replace the product moments by sample covariances.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 3.548279\n"
     ]
    }
   ],
   "source": [
    "beta = cov(Y,I)/cov(X,I)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They do indeed coincide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Solution 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] C. Kleiber, A. Zeileis (2008). Applied Econometrics with R. Springer-Verlag New York.\n",
    "\n",
    "[2] M. Eaton, M. D. Perlman (1973). The nonsingularity of generalized sample covariance\n",
    "matrices. Annals of Statistics - ANN STATIST, 1, 07 1973. doi: 10.1214/aos/1176342465."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
